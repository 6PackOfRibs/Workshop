## Blumenstock Response

Jimmy Yao

1/28/2020

## Describe the promise, pitfalls and ways forward Blumenstock uses as the foundation for his thesis. How do you respond to these ideas regarding “good intent”, “transparency” and the difficult “balancing act” when considering the intersection of human development with data science?

The promise of data science Blumenstock mentioned is indeed impressive. He made an excellent point regarding how data is already being used in important ways such as generating credit scores for those who need them but lack collateral and access to a bank. Algorithms used by companies such as Google and Facebook for advertising could be utilized to determine who is most in need of help, and the same concept could be applied to helping people after a natural disaster. That being said, it is important that when action is taken, it is done right.

The pitfalls Blumenstock describes are, in my opinion, not so much as traps we unknowingly walk into, and more like walking the opposite way we want to be going. Unanticipated effects, I can see as being a pitfall. After all, seeing as we are not omniscient, we cannot possibly know the full extent of the effects our actions will have. Lack of validation is something I would place under carelessness. After all, medicines are tested for around 10 years before being released. Naturally, we might not need that level of validation, but there should be a reasonable amount of validation before an approach is used for something important. Undoubtedly, there will still be new issues with the approach found after being used. However, that is not a problem, but something due to the fact that the approach is new, and one of the costs of progress. Biased algorithms and data sets are frustrating. I usually want to attribute the problem with the people who made the algorithms or gathered the data, but the truth is it's often very difficult to measure something with so many factors such as poverty and end up with an accurate result.

I see lack of regulation as a very big issue. People who possibly have their own agendas not being transparent or held accountable for their actions are not people I would want getting so much potentially sensitive data. In this case, good intent is very important. Obviously, good intent in and of itself is not enough, but it is the bare minimum I would want from someone who has access to so much data. If someone had the intelligence and foresight to use the data to its fullest capacity, but not good intent, then... that's really bad. Transparency is good, but oftentimes not necessary. It would be great to have people with good intentions who are unafraid of sharing their activities, but some good activities, by their very nature, should not be shared. If it is better for me not to know, then I don't want to know it. When balancing moral issues with data science, I would consider both the end result and the process and determine which combination would have the greatest benefit. For example, if at the end of a project, we have world peace, but in the process we had to kill a million people, that would not be okay. When considering the intersection of human development and data science, it is important to find the combination with the greatest benefit to society and the least cost to morality. In which case, I believe our current system with more regulations would be the best. I don't particularly agree that new sources of data should complement old sources of data, since that kind of defeats the purpose of taking a new approach. Customizing, I feel is already being done. People take already developed algorithms and use them for different purposes whenever the feel like it is efficient. In any case, I believe society as it currently is is efficient, and that we should focus on lowering the cost to society and morality through regulations.
